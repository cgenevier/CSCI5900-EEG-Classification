{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b97536f",
   "metadata": {},
   "source": [
    "### Matlab Datastructure\n",
    "```\n",
    "Subject01_s1.mat\n",
    "│\n",
    "│  MATLAB .mat file for ONE subject + ONE session\n",
    "│  Contains multiple recording runs (blocks) of continuous EEG\n",
    "│\n",
    "└── run  (cell array / list, length = 10)\n",
    "    │\n",
    "    │  Each cell corresponds to ONE continuous recording run\n",
    "    │  (e.g., separate blocks to reduce fatigue or reset tasks)\n",
    "    │\n",
    "    ├── run{1} (struct)\n",
    "    │   │\n",
    "    │   │  One run = one uninterrupted EEG recording\n",
    "    │   │\n",
    "    │   ├── eeg : [n_samples x n_channels] numeric matrix\n",
    "    │   │   │\n",
    "    │   │   │  The raw EEG signal\n",
    "    │   │   │  - rows    = time samples (uniformly sampled)\n",
    "    │   │   │  - columns = EEG channels / electrodes\n",
    "    │   │   │  Value = voltage at that channel & time point\n",
    "    │   │   │\n",
    "    │   │   │  Example:\n",
    "    │   │   │    eeg(1000, 5) → channel 5 voltage at sample 1000\n",
    "    │   │   │\n",
    "    │   └── header : struct\n",
    "    │       │\n",
    "    │       │  Metadata describing how to interpret the EEG\n",
    "    │       │  (who, how, when, and where events occurred)\n",
    "    │       │\n",
    "    │       ├── Subject\n",
    "    │       │   │\n",
    "    │       │   │  Subject identifier (ID or label)\n",
    "    │       │\n",
    "    │       ├── Session\n",
    "    │       │   │\n",
    "    │       │   │  Session identifier (e.g., \"s1\")\n",
    "    │       │   │  Useful when subjects have multiple sessions\n",
    "    │       │\n",
    "    │       ├── SampleRate\n",
    "    │       │   │\n",
    "    │       │   │  Sampling frequency in Hz\n",
    "    │       │   │  Defines time resolution (e.g., 512 samples/sec)\n",
    "    │       │\n",
    "    │       ├── Label\n",
    "    │       │   │\n",
    "    │       │   │  Channel labels / electrode names\n",
    "    │       │   │  Length = n_channels\n",
    "    │       │   │  Column names for eeg matrix\n",
    "    │       │\n",
    "    │       └── EVENT : struct\n",
    "    │           │\n",
    "    │           │  Event markers embedded in the continuous EEG\n",
    "    │           │  Used to align cognitive events with the signal\n",
    "    │           │\n",
    "    │           ├── POS : [n_events x 1] vector\n",
    "    │           │   │\n",
    "    │           │   │  Sample indices (MATLAB 1-based)\n",
    "    │           │   │  Indicate *when* an event occurred in this run\n",
    "    │           │\n",
    "    │           └── TYP : [n_events x 1] vector\n",
    "    │               │\n",
    "    │               │  Event type / trigger code\n",
    "    │               │  Encodes *what kind* of event occurred\n",
    "    │               │  (e.g., correct response vs error response)\n",
    "    │\n",
    "    ├── run{2}\n",
    "    │   │\n",
    "    │   │  Same structure as run{1}, but for the next recording block\n",
    "    │\n",
    "    └── ...\n",
    "        │\n",
    "        │  Additional runs, all with identical internal structure\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c49ab",
   "metadata": {},
   "source": [
    "### Output Structure\n",
    "\n",
    "#### Brain Imaging Data Structure (out_bids directory)  \n",
    "Contains the canonical, read-only source EEG data stored in BrainVision format, organized according to the BIDS specification. These files are never modified after export and serve as the single source of truth for the dataset.\n",
    "```\n",
    "out_bids/\n",
    "└── sub-01/\n",
    "    └── ses-01/\n",
    "        └── eeg/\n",
    "            ├── sub-01_ses-01_task-errp_run-01_eeg.vhdr\n",
    "            ├── sub-01_ses-01_task-errp_run-01_eeg.eeg\n",
    "            ├── sub-01_ses-01_task-errp_run-01_eeg.vmrk\n",
    "            ├── sub-01_ses-01_task-errp_run-01_events.tsv\n",
    "            ├── sub-01_ses-01_task-errp_run-01_channels.tsv\n",
    "            └── sub-01_ses-01_task-errp_run-01_eeg.json  ← never edited\n",
    "```\n",
    "\n",
    "#### \"Working\" FIF files (out_fif directory)\n",
    "Contains MNE-native working copies of the data for preprocessing, filtering, referencing, and rapid iteration. Multiple FIF files may exist simultaneously, each corresponding to a different preprocessing pipeline or experimental configuration.\n",
    "```\n",
    "out_fif/\n",
    "└── sub-01/\n",
    "    └── ses-01/\n",
    "        ├── errp_bp1-20_car_raw.fif\n",
    "        ├── errp_bp0.1-40_car_raw.fif        ← alternative bandpass\n",
    "        ├── errp_bp1-20_laplacian_raw.fif    ← alternative referencing\n",
    "        ├── errp_minimal_raw.fif             ← minimal preprocessing\n",
    "        └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6499b34",
   "metadata": {},
   "source": [
    "#### Pipeline Notes\n",
    "\n",
    "```\n",
    "FIF (Raw)\n",
    "  ↓\n",
    "Preprocessing\n",
    "  ↓\n",
    "Epoching (time-lock to events)\n",
    "  ↓\n",
    "Artifact handling\n",
    "  ↓\n",
    "Feature representation\n",
    "  ↓\n",
    "Model training\n",
    "  ↓\n",
    "Evaluation / generalization tests\n",
    "```\n",
    "Stage-by-stage: what you actually do with FIFs\n",
    "\n",
    "Stage A — Load & inspect (QC)\n",
    "\n",
    "Goal: verify nothing is broken before analysis.\n",
    "\n",
    "You typically:\n",
    "\t•\tload Raw\n",
    "\t•\tplot raw traces\n",
    "\t•\tplot PSD\n",
    "\t•\tverify event timing\n",
    "\t•\tsanity-check channel count and names\n",
    "\n",
    "Nothing is modified yet — this is inspection only.\n",
    "\n",
    "⸻\n",
    "\n",
    "Stage B — Preprocessing (continuous domain)\n",
    "\n",
    "Goal: clean the signal without destroying ErrPs\n",
    "\n",
    "Typical ErrP-appropriate steps:\n",
    "\t•\tBand-pass filter (e.g. 0.1–30 Hz)\n",
    "\t•\tPossibly notch (50/60 Hz) — BioSemi often doesn’t need it\n",
    "\t•\tRe-reference (common average is typical)\n",
    "\t•\tOptional downsampling (512 → 256 Hz is common)\n",
    "\n",
    "Still continuous Raw, just cleaner.\n",
    "\n",
    "Key principle:\n",
    "\n",
    "Preprocess before epoching, and do it identically across files.\n",
    "\n",
    "⸻\n",
    "\n",
    "Stage C — Epoching (critical step)\n",
    "\n",
    "Goal: convert continuous EEG into trials suitable for classification.\n",
    "\n",
    "You:\n",
    "\t•\tchoose event codes (e.g. correct vs error)\n",
    "\t•\tdefine time window (e.g. −200 ms → +800 ms)\n",
    "\t•\tbaseline-correct\n",
    "\t•\treject obviously bad epochs\n",
    "\n",
    "This is where:\n",
    "\t•\tRaw → Epochs\n",
    "\t•\tshape becomes (n_epochs, n_channels, n_times)\n",
    "\n",
    "This is the canonical ML-ready representation.\n",
    "\n",
    "⸻\n",
    "\n",
    "Stage D — Artifact handling\n",
    "\n",
    "Goal: remove or mitigate noise without leaking labels.\n",
    "\n",
    "Options (choose carefully for ErrP):\n",
    "\t•\tSimple amplitude-based rejection\n",
    "\t•\tICA (optional, often overkill for ErrP)\n",
    "\t•\tEOG channel regression (if available)\n",
    "\n",
    "Many ErrP papers use minimal artifact removal to avoid bias.\n",
    "\n",
    "⸻\n",
    "\n",
    "Stage E — Feature representation\n",
    "\n",
    "This is where model families diverge.\n",
    "\n",
    "From the same Epochs, you might create:\n",
    "\n",
    "1. Time-domain features\n",
    "\t•\tRaw voltage samples\n",
    "\t•\tChannel × time flattened vectors\n",
    "\t•\tMean / peak amplitude in windows\n",
    "\n",
    "→ good for LDA / sLDA / logistic regression\n",
    "\n",
    "2. Spatial features\n",
    "\t•\tCSP (less common for ErrP, but possible)\n",
    "\t•\txDAWN (very common for ERP / ErrP)\n",
    "\n",
    "→ good for LDA, linear SVM\n",
    "\n",
    "3. Time–frequency\n",
    "\t•\tMorlet wavelets\n",
    "\t•\tBandpower features\n",
    "\n",
    "→ good for tree-based or nonlinear models\n",
    "\n",
    "4. Deep learning inputs\n",
    "\t•\t(channels × time) tensors\n",
    "\t•\t(channels × time × 1) for CNNs\n",
    "\n",
    "→ good for CNNs, temporal convnets\n",
    "\n",
    "⸻\n",
    "\n",
    "Stage F — Model training\n",
    "\n",
    "Goal: learn to discriminate error vs correct.\n",
    "\n",
    "Typical models in ErrP literature:\n",
    "\t•\tsLDA (gold standard baseline)\n",
    "\t•\tLogistic regression\n",
    "\t•\tLinear SVM\n",
    "\t•\tShallow CNNs (EEGNet-style)\n",
    "\t•\tTemporal CNNs\n",
    "\n",
    "Important:\n",
    "\t•\tcross-validation must respect runs / sessions / subjects\n",
    "\t•\tavoid trial leakage\n",
    "\n",
    "⸻\n",
    "\n",
    "Stage G — Evaluation & generalization\n",
    "\n",
    "You’ll typically test:\n",
    "\t•\twithin-session performance\n",
    "\t•\tcross-session generalization\n",
    "\t•\tcross-subject generalization (hardest)\n",
    "\n",
    "Metrics:\n",
    "\t•\taccuracy\n",
    "\t•\tbalanced accuracy\n",
    "\t•\tROC-AUC\n",
    "\t•\tconfusion matrices\n",
    "\n",
    "```\n",
    "raw_fif/            ← your current output (do not touch)\n",
    "preprocessed_fif/   ← filtered / rereferenced raw\n",
    "epochs/             ← Epochs saved as .fif\n",
    "features/           ← numpy arrays, torch tensors\n",
    "models/             ← trained classifiers\n",
    "results/            ← metrics, plots\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fdfd77",
   "metadata": {},
   "source": [
    "### Pre-processing Notes\n",
    "\n",
    "Preprocessing that should be done on raw continuous EEG (these operations assume continuity and stationarity):  \n",
    "\t•\tBandpass filtering  \n",
    "\t•\tNotch filtering (50/60 Hz)  \n",
    "\t•\tRe-referencing (average, mastoids)  \n",
    "\t•\tArtifact correction via ICA (if used)  \n",
    "\n",
    "Why?  \n",
    "\t•\tFiltering across epoch boundaries causes edge artifacts  \n",
    "\t•\tICA needs long continuous data  \n",
    "\t•\tRe-referencing should be consistent across the recording  \n",
    "\n",
    "Raw EEG --> Filter / Rereference --> Epoch  \n",
    "\n",
    "Preprocessing that is usually done on epoched data (these are trial-specific):  \n",
    "\t•\tBaseline correction  \n",
    "\t•\tEpoch rejection (amplitude thresholds, peak-to-peak)  \n",
    "\t•\tTrial-wise normalization  \n",
    "\t•\tFeature extraction  \n",
    "\n",
    "For ML:  \n",
    "\t•\tZ-scoring across time  \n",
    "\t•\tChannel-wise normalization  \n",
    "\t•\tSpatial filters (e.g., xDAWN, CSP) — often applied to epochs  \n",
    "\n",
    "A very ML-relevant caveat: for classification, some models perform better with minimal preprocessing  \n",
    "CNNs especially can learn:  \n",
    "\t•\tbaseline offsets  \n",
    "\t•\tfrequency filters  \n",
    "\t•\tspatial combinations  \n",
    "\n",
    "So, over-cleaning can remove signal your model could exploit. This is why many modern ErrP pipelines:  \n",
    "\t•\tapply only bandpass + notch  \n",
    "\t•\tskip aggressive artifact rejection  \n",
    "\t•\tlet the classifier handle variability  \n",
    "\n",
    "Recommended Workflow:  \n",
    "Raw EEG  \n",
    "  → bandpass + notch  \n",
    "  → rereference  \n",
    "  → epoch with varied tmin/tmax  \n",
    "  → optional baseline (or not)  \n",
    "  → model-specific normalization  \n",
    "  → classification"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
